{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Encoding of outputs\n",
    "* Encoding of output can impact performance.\n",
    "* Common encoding methods for classification:\n",
    "    - Integer label for each class\n",
    "    - One-hot enconding (binary vectors with one indicator for each class)\n",
    "    - Binary (or other base) encoding \n",
    "* Similar choices can be made for regression and other problems\n",
    "\n",
    "### Rate of Learning\n",
    "\n",
    "* Back-propagation algorithm provides an approximation to the trajectory in the weight space computed by the method of steepest descent\n",
    "*  Small $\\eta$: smoother trajectory, slower learning\n",
    "*  Too Large $\\eta$: large changes in the synaptic weights, may become unstable (oscillatory)\n",
    "\n",
    "\n",
    "*  *Include a momentum term*: tries to increase rate of learning while avoiding instability\n",
    "* Recall: $\\Delta w_{ij}(n) = \\eta \\delta_j(n) y_i(n) = \\eta \\frac{\\partial E(n)}{\\partial v_j(n)} y_i(n)$ \n",
    "*  *The Generalized Delta rule (Delta rule with momentum):* $\\Delta w_{ij}(n) = \\alpha \\Delta w_{ij}(n-1) + \\eta \\delta_j(n) y_i(n)$\n",
    "*  Can write the generalized delta rule as a time series (index $t$):\n",
    "\\begin{eqnarray}\n",
    "\\Delta w_{ij}(n) &=& -\\eta \\sum_{t=0}^n \\alpha^{(n-t)}\\delta_j(t)y_i(t)\\\\\n",
    "&=& -\\eta \\sum_{t=0}^n \\alpha^{(n-t)} \\frac{\\partial E(t)}{\\partial w_{ij}(t)}\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "#### Observations & Comments:\n",
    "*  $\\Delta w_{ij}(n)$ is the sum of exponentially weighted time series.  For it to converge, $0 \\le |\\alpha| < 1$, If $\\alpha = 0$, then you are operating without momentum\n",
    "*  Inclusion of momentum accelerate descent in steady downhill directions\n",
    "*  Inclusion of momentum has a stabilizing effect in directions that oscillate in sign\n",
    "*  Momentum may prevent termination/convergence in a shallow minimum\n",
    "*  The learning rate *can* be connection dependent, $\\eta_{ij}$, can even set it to zero for some connections\n",
    "\n",
    "*See Haykin's Neural Network text for more reading on this and the following.  It was the reference for these notes and provides a nice description. \n",
    "\n",
    "\n",
    "### Online vs. Batch Update\n",
    "\n",
    "* Thus far we have focused on Online learning. *What is meant by online learning?*\n",
    "* You can also do:  Batch update or (Stochastic) Mini-Batch Update\n",
    "\n",
    "\n",
    "### A Sampling of Heuristics/Methods that may help Back-Propagation Algorithm Perform Better\n",
    "\n",
    "* Maximizing Information Content\n",
    "     * Provide training samples that provide the largest information content\n",
    "    * Use example with largest training error\n",
    "    * Use example radically different than the ones before\n",
    "    * Emphasizing scheme, present more difficult patterns to the network, difficulty is determined by error\n",
    "    * Problems with emphasizing scheme:\n",
    "        * Distribution of samples in an epoch is distorted\n",
    "        * Outliers or mislabeled samples can cause major problems\n",
    "\n",
    "*  Activation Function: MLPs may learn better with activation functions that are antisymmetric rather than nonsymmetric. \n",
    "\\begin{equation}\n",
    "\\phi(-v) = -\\phi(v)\n",
    "\\end{equation}\n",
    "\n",
    "* Target values need to be in the range of the sigmoid. \n",
    "* It is good if the input variables are uncorrelated\n",
    "* It is good if variances are approximately equal\n",
    "\n",
    "### Strategy when training a network for the first time\n",
    "\n",
    "* This is a good read.  Includes suggestions that I often give students and agree with:  http://karpathy.github.io/2019/04/25/recipe/\n",
    "* Most commonly overlooked in my experience are:\n",
    "    - Be sure you know and understand your data.  Make use of any knowledge you have or gain about the problem. For example, if you realize you have an imbalanced data set, you may want to implement a method to address this such as upsampling/data augmentation for the smaller class, weighting the examples from each class accordingly, or another approach. \n",
    "    - Overfit your network with a small subset of the data.  This helps to make sure your code is working, alert you to any bugs or issues in the data. \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "### Network Pruning Techniques\n",
    "\n",
    "*  *Network Growing:* Start with a small MLP and add to it when unable to meet design specifications\n",
    "*  *Network Pruning:* Start with a large MLP and prune it by eliminating weights (driving them to zero)\n",
    "\n",
    "*  *Regularization:* Just as we applied regularization during regression, we can apply regularization to our NN training: $R(w) = E_s(w) + \\lambda E_c(w)$ where $E_s$ is the error measure, $E_c$ is the regularization penalty term, and $\\lambda$ is a regularization \"trade-off\" parameter\n",
    "     * $\\lambda = 0$: Training based only on error and training data\n",
    "     * $\\lambda \\rightarrow \\infty$: Training samples are unreliable, Minimize complexity\n",
    "\n",
    "#### Weight Decay\n",
    "\\begin{equation}\n",
    "E_c(w) = \\left\\| \\mathbf{w} \\right\\|^2 = \\sum_i w_i^2\n",
    "\\end{equation}\n",
    "* Drives some weights to be small. \n",
    "* Weights with little or no influence are excess/unnecessary weights.  The goal: encourage unnecessary weights to go to zero and thereby improve generalization\n",
    " or at least have the smallest values that can solve the problem. \n",
    "\n",
    "* *So, how would you include weight decay in your Back-Propagation Training Algorithm?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ill-conditioned Data\n",
    "\n",
    "* Consider the following two systems of linear equations:\n",
    "\\begin{eqnarray}\n",
    " x_1 + 2x_2 = 2\\\\\n",
    " x_1 + 2.0001x_2 = 2\n",
    " \\end{eqnarray}\n",
    "\n",
    " \\begin{eqnarray}\n",
    " x_1 + 2x_2 = 2\\\\\n",
    " x_1 + 2.0001x_2 = 2.0001\n",
    " \\end{eqnarray}\n",
    "\n",
    "* *What are the solutions to both of these linear systems?*\n",
    "\n",
    "* Ill-conditioned problems mean that small changes in values result in a large change in the solution.  This is related to *adversarial examples* in deep learning architectures. See: https://blog.openai.com/adversarial-example-research/  Adversarial examples are also related to the Curse of Dimensionality. \n",
    "\n",
    "* Ill-conditioned data poses problems for MLPs as well.  Ill-conditioning affects the speed and accuracy of back-propagation. \n",
    "* The *condition number* is the ratio of the largest and smallest eigenvalues of the Hessian of the error function. \n",
    "* *What is the Hessian of the least squared error function for the simple linear example shown above?*\n",
    "* *What are the condition numbers for the following data sets:*\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\mathbf{X} = [-1.5, 1; -0.5, 1; 0.5, 1; 1.5, 1]\\\\\n",
    "\\mathbf{Y} = [1.5; 2.5; 3.5; 4.5]\n",
    "\\end{eqnarray}\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\mathbf{X} = [0, 1; 1, 1; 2, 1; 3, 1]\\\\\n",
    "\\mathbf{Y} = [3; 4; 5; 6]\n",
    "\\end{eqnarray}\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\mathbf{X} = [10, 1; 11, 1; 12, 1; 13, 1]\\\\\n",
    "\\mathbf{Y} = [13; 14; 15; 16]\n",
    "\\end{eqnarray}\n",
    "\n",
    "* The Hessian matrix describes the local curvature of the error surface. Ill conditioned data have eccentric error contours (where as well conditioned data will have circular or nearly circular error contours).\n",
    "\n",
    "* It is also good to have similar variances across input values and have node-specific learning weights.  Consider a linear network.  Suppose you have one input value with an average of $\\approx 3000$, a bias fixed to 1 and a target value around $\\approx 30$. Then, the weight for the input must be small to map 3000 to 30 (.001). If we had a $10\\%$ error, then we would end up needing a very small learning rate to avoid instability.  However, if we had such a small learning rate and our bias was also wrong, then it would take extremely long to train. \n",
    "\n",
    "* We also don't want to saturate our activation functions as this leads to very slow learning.  So, initialize weights appropriately and normalize input data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Some helpful visualizations to check out:\n",
    " \n",
    "* https://playground.tensorflow.org\n",
    "* https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "* http://experiments.mostafa.io/public/ffbpann/\n",
    "* https://google-developers.appspot.com/machine-learning/crash-course/backprop-scroll/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
