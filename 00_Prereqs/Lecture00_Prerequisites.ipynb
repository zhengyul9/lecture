{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisite Material for Foundations of Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The following includes of list a topics that you should know to succeed in this course. \n",
    "* This covers material from calculus, linear algebra, statistics, and programming in Python.  \n",
    "* Please review the following material carefully.  \n",
    "* If you do not feel confident in all of the following material, you may want to reconsider taking the course at this time. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Review\n",
    "\n",
    "Some Python tutorials and references to go over are: \n",
    "\n",
    "* Learn Python the hard way: https://learnpythonthehardway.org/python3/\n",
    "* Python for absolute beginners: https://www.youtube.com/playlist?list=PLS1QulWo1RIaJECMeUT4LFwJ-ghgoSH6n\n",
    "* Python Docs tutorial: https://docs.python.org/3/tutorial/\n",
    "* Numpy quickstart tutorial: https://docs.scipy.org/doc/numpy/user/quickstart.html\n",
    "    \n",
    "- Python For Data Science - A Cheat Sheet For Beginners: https://www.datacamp.com/community/tutorials/python-data-science-cheat-sheet-basics\n",
    "- Other Python Cheat Sheets: https://towardsdatascience.com/collecting-data-science-cheat-sheets-d2cdff092855 (Credits to Karlijn Willems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculus Review\n",
    "\n",
    "Calculus topics to review include:\n",
    "\n",
    "* Derivatives: https://www.youtube.com/watch?v=9vKqVkMQHKk&list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr&index=2\n",
    "* Chain rule and product rule: https://www.youtube.com/watch?v=YG15m2VwSjA&list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr&index=4\n",
    "* Integration: https://www.youtube.com/watch?v=rfG8ce4nNh0&list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr&index=8\n",
    "* Taylor Series: https://www.youtube.com/watch?v=3d6DsjIBzJ4&list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr&index=11\n",
    "\n",
    "Additional resources:\n",
    "* Full 3Blue1Brown Calculus series: https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr\n",
    "* ML-CheatSheet for Calculus: https://ml-cheatsheet.readthedocs.io/en/latest/calculus.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra Review\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics and definitions to know include: \n",
    "  * Vector: https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=2&t=0s\n",
    "  \\begin{equation} \\mathbf{x} = \\left[ \\begin{array}{c} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_D\\end{array} \\right] \\end{equation}\n",
    "  * Matrix: \n",
    "  \\begin{equation}\n",
    "  \\mathbf{X}  = \\left[\\!\\begin{array}{c c c c}\n",
    "    x_{11} & x_{12} & \\cdots & x_{1n}\\\\\n",
    "    x_{21} & x_{22} & \\cdots & x_{2n}\\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "    x_{d1} & x_{d2} & \\cdots & x_{dn}\\end{array}\\!\\right]\\! \\!\\in\\! \\mathcal{R}^{d \\times n}\n",
    "  \\end{equation}\n",
    "  * Transpose operation: \n",
    "    \\begin{equation}\n",
    "\t\t \\mathbf{x}^T = \\left[  x_1,  x_2 , \\cdots , x_D \\right]\n",
    "         \\end{equation}\n",
    "         \n",
    "    \\begin{equation}\\left(\\mathbf{A}^T\\mathbf{B}\\right)^T = \\mathbf{B}^T\\mathbf{A}\\end{equation}\n",
    "         \n",
    "  * Vector/Matrix scaling:  Given a vector $\\mathbf{x} \\in \\mathbb{R}^D$ and a scalar value $a$, *what is $a\\mathbf{x}$?*  *What does this operation do geometrically?* \n",
    "  * Vector/Matrix addition: Given $\\mathbf{x} \\in \\mathbb{R}^D$ and $\\mathbf{y} \\in \\mathbb{R}^D$, *what is $\\mathbf{x} + \\mathbf{y}$?  What is the geometric interpretation?*\n",
    "  * Vector/Matrix subtraction: Given $\\mathbf{x} \\in \\mathbb{R}^D$ and $\\mathbf{y} \\in \\mathbb{R}^D$, *what is $\\mathbf{x} - \\mathbf{y}$? What is the geometric interpretation?*\n",
    "  * Inner product: $\\mathbf{x}^T\\mathbf{y} = \\mathbf{y}^T\\mathbf{x} = \\sum_{i=1}^D x_iy_i$\n",
    "  * Outer product: $xy^\\top \\!=\\! \\left[\\!\\begin{array}{c}\n",
    "x_1\\\\\n",
    "x_2\\\\\n",
    "\\vdots\\\\\n",
    "x_d\\end{array}\\!\\right]\\!\\!\n",
    "\\left[\\!\\begin{array}{c}\n",
    "y_1\\\\\n",
    "y_2\\\\\n",
    "\\vdots\\\\\n",
    "y_n\\end{array}\\!\\right]^\\top \\!\\!=\\! \\left[\\!\\begin{array}{c c c c}\n",
    "x_1y_1 & x_1y_2 & \\cdots & x_1y_n\\\\\n",
    "x_2y_1 & x_2y_2 & \\cdots & x_2y_n\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "x_dy_1 & x_dy_2 & \\cdots & x_dy_n\\end{array}\\!\\right]\\! \\!\\in\\! \\mathcal{R}^{d \\times n}.\n",
    "$\n",
    "* Linear transformations: https://www.youtube.com/watch?v=kYB8IZa5AuE&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=3\n",
    "* Inverse: https://www.youtube.com/watch?v=uQhTuRlWMxw&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=7\n",
    "\n",
    "* L-p norm: Given a vector, $\\mathbf{x}$ and a $p$-value, the $l_p$ norm is defined as:\n",
    "\\begin{eqnarray}\n",
    "\\left\\|\\mathbf{x}\\right\\|_p = \\left( \\sum_{d=1}^D |x_d|^p \\right)^{\\frac{1}{p}}\n",
    "\\end{eqnarray}\n",
    "\n",
    "So, if $p=2$, then the $l_2$ norm of a vector is:\n",
    "\\begin{eqnarray}\n",
    "\\left\\|\\mathbf{x}\\right\\|_2 = \\left( \\sum_{d=1}^D |x_d|^2 \\right)^{\\frac{1}{2}}\n",
    "\\end{eqnarray}\n",
    "\n",
    "* Eigenvectors and Eigenvalues:  https://www.youtube.com/watch?v=PFDu9oVAE-g&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=14\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associated python code to review some of the concepts listed above.  \n",
    "\n",
    "import numpy as np\n",
    "a = 2\n",
    "x = np.array([[1],[2],[3]])\n",
    "y = np.array([[4],[5],[6]])\n",
    "\n",
    "#Print Vector x\n",
    "print('x:',x)\n",
    "\n",
    "#Transpose Vector x\n",
    "print('x.T:',x.T)\n",
    "\n",
    "#Scale Vector x with scalar a\n",
    "print('a*x:', a*x)\n",
    "\n",
    "#Vector addition\n",
    "print('x+y:', x+y)\n",
    "\n",
    "#Vector subtraction\n",
    "print('y-x:',y-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Several ways to compute the inner product of vectors x and y in python/numpy\n",
    "\n",
    "#First by using matrix multiplication operator '@' that numpy supports:\n",
    "print(x.T@y)\n",
    "print(y.T@x)\n",
    "\n",
    "#Second with numpy.matmul function for matrix maultiplication:\n",
    "print(np.matmul(x.T,y))\n",
    "print(np.matmul(y.T,x))\n",
    "\n",
    "#Third with numpy.inner function:\n",
    "print(np.inner(x.T,y.T))\n",
    "\n",
    "#Fourth with numpy.dot function, note that numpy.dot acts the same as '@ ' or 'np.matmul' for 2D arrays:\n",
    "print(x.T.dot(y))\n",
    "print(y.T.dot(x))\n",
    "\n",
    "#for 1D arrays, acts similar to numpy.inner function:\n",
    "print(np.dot([1,2,3],[4,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the outer product of vectors x and y\n",
    "print(np.outer(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.outer(x,y).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute l-p norm for p = 2, 3, 1\n",
    "x = np.array([1, 2, 3])\n",
    "print(np.linalg.norm(x,ord=2))\n",
    "print((x@x)**(1/2))\n",
    "print(np.linalg.norm(x,ord=3))\n",
    "print(np.linalg.norm(x,ord=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute l-p norm for p = 2, 3, 1, 0\n",
    "x = np.array([-1, -2, -3])\n",
    "print(np.linalg.norm(x,ord=2))\n",
    "print((x@x)**(1/2))\n",
    "print(np.linalg.norm(x,ord=3))\n",
    "print(np.linalg.norm(x,ord=1))\n",
    "print(np.linalg.norm(x,ord=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute l-p norm for p = 2, 3, 1, 0\n",
    "x = np.array([-1, 0, 3])\n",
    "print(np.linalg.norm(x,ord=2))\n",
    "print((x@x)**(1/2))\n",
    "print(np.linalg.norm(x,ord=3))\n",
    "print(np.linalg.norm(x,ord=1))\n",
    "print(np.linalg.norm(x,ord=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note the notation:  \n",
    "   * scalar values are unbolded (e.g., $N$, $x$)\n",
    "   * vectors are lower case and bolded (e.g., $\\mathbf{x}$)\n",
    "   * matrices are uppercase and bolded (e.g., $\\mathbf{A} \\in \\mathbb{R}^{D \\times N}$)\n",
    "   * vectors are generally assumed to be column vectors (e.g., $\\mathbf{x}^T = \\left(x_1, \\ldots, x_N\\right)$ and $\\mathbf{x} =  \\left(x_1, \\ldots, x_N\\right)^T$ )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional reading and videos to review linear algebra concepts:\n",
    "\n",
    "* Strang, Gilbert, et al. Introduction to linear algebra. Vol. 4. Wellesley, MA: Wellesley-Cambridge Press, 2009.\n",
    "    Chapters 1-7\n",
    "    \n",
    "* Lay, David C. \"Linear Algebra and its Applications, 3rd updated Edition.\" (2005).\n",
    "\n",
    "* MITOpenCourseWare Linear Algebra:  https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/\n",
    "        \n",
    "* 3Blue1Brown Linear Algebra Review:  https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab\n",
    "\n",
    "* SciPy Cheat Sheet: Linear Algebra in Python: https://www.datacamp.com/community/blog/python-scipy-cheat-sheet\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics Review\n",
    "\n",
    "Topics and definitions to know include:\n",
    "\n",
    "- Likelihood and Probability\n",
    "- Expected Value: https://www.youtube.com/watch?v=j__Kredt7vY\n",
    "- Variance and covariance: https://www.youtube.com/watch?v=ualmyZiPs9w\n",
    "- Random variables: https://www.youtube.com/watch?v=3v9w79NhsfI\n",
    "- Probability density functions: https://www.youtube.com/watch?v=Fvi9A_tEmXQ\n",
    "- Marginal and conditional probability: https://www.youtube.com/watch?v=CAXQvTKP8sg\n",
    "- Independence and conditional independence: https://www.youtube.com/watch?v=uzkc-qNVoOk\n",
    "- Normal/Gaussian distribution: https://www.youtube.com/watch?v=hgtMWR3TFnY\n",
    "- Central Limit Theorem: https://www.youtube.com/watch?v=JNm3M9cqWyc\n",
    "- Bayes' Rule: https://www.youtube.com/watch?v=XQoLVl31ZfQ\n",
    "\n",
    "Additional Reading: Goodfellow, I. et al. \"Deep Learning\", MIT Press, 2016. Chapter 3: Probability and Information Theory, Pages 51-70. http://www.deeplearningbook.org/contents/prob.html"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
