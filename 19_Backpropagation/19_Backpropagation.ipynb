{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Approximation Theorem: \n",
    "\n",
    "Let $\\phi(\\cdot)$ be a non-constant, bounded and monotone-increasing continuous function.  Let $I_{m_0}$ denote the $m_0$-dimensional unit hypercube $[0, 1]^{m_0}$.  The space of continuous functions on $I_{m_0}$ is denoted by $C(I_{m_0})$.  Then, given any function $f \\in C(I_{m_0})$ and $\\epsilon > 0$, there exists an integer $m_1$ and sets of real constants $\\alpha_i, \\beta_i,$ and $w_{ij}$, where $i = 1, \\ldots, m_1$ and $j = 1, \\ldots, m_0$ such that we may define\n",
    "\\begin{equation}\n",
    "F(x_1, \\ldots, x_{m_0}) = \\sum_{i=1}^{m_1} \\alpha_i \\phi\\left( \\sum_{j=1}^{m_0} w_{ij}x_j + b_i\\right)\n",
    "\\end{equation}\n",
    "as an approximation realization of the function $f(\\cdot)$: that is, \n",
    "\\begin{equation}\n",
    "\\left| F(x_1, \\ldots, x_{m_0}) - f(x_1, \\ldots, x_{m_0}) \\right| < \\epsilon\n",
    "\\end{equation}\n",
    "for all $x_1, x_2, \\ldots, x_{m_0}$ in the input space.\n",
    "\n",
    "* Essentially, the Universal Approximation Theorem states that a single hidden layer is sufficient for a multilayer perceptron to compute a uniform $\\epsilon$ approximation to a given training set - provided you have the *right* number of neurons and the *right* activation function.  (However, this does not say that a single hidden layer is optimal with regards to learning time, generalization, etc.)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background for Error Back-Propagation\n",
    "\n",
    "* Error Back-Propagation is based on *gradient descent*.\n",
    "* Let's review/learn gradient descent:\n",
    "\n",
    "*Method of Gradient/Steepest Descent:*\n",
    "\n",
    "*move in direction opposite to the gradient vector, $g = \\bigtriangledown E(\\mathbf{w})$\n",
    "\\begin{eqnarray}\n",
    "w(n+1) &=& w(n) - \\eta g(n)\\\\\n",
    "\\Delta w(n) &=& w(n+1) - w(n)\\\\\n",
    "\\Delta w(n) &=& - \\eta g(n) \\quad \\text{ Error correction rule }\n",
    "\\end{eqnarray}\n",
    "* Show that using steepest descent, $E(\\mathbf{w}(n+1)) < E(\\mathbf{w}(n)) $\n",
    "*  Recall: Taylor Series Expansion: $f(x) = f(a) + f'(a)(x-a) + \\frac{f''(a)}{2!}(x-a)^2 + ....$\n",
    "* Approximate $E(\\mathbf{w}(n+1))$ with Taylor Series around $w(n)$\n",
    "\\begin{eqnarray}\n",
    "E(w(n+1)) &\\approx& E(w(n)) + \\Delta E(w(n))(w(n+1) - w(n))\\\\\n",
    "&\\approx& E(w(n)) + g^T(n)(\\Delta w(n)) \\rightarrow \\text{So, we should align $\\Delta w(n)$ with $-g(n)$}\\\\\n",
    "&\\approx& E(w(n)) - \\eta g^T(n)g(n)\\\\\n",
    "&\\approx& E(w(n)) - \\eta \\left\\| g(n) \\right\\|^2\n",
    "\\end{eqnarray}\n",
    "* For positive, small $\\eta$, the cost function is decreased\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Back-propagation\n",
    "\n",
    "* There are many approaches to train a neural network.  \n",
    "* One of the most commonly used is the *Error Back-Propagation Algorithm*.\n",
    "\n",
    "\n",
    "* Two kinds of signals:\n",
    "    1. Function Signals: presumed to perform useful function at the output of the network, also called input signal\n",
    "    2.  Error Signals: propagates backwards, involves an error-dependent function \n",
    "\n",
    "* Each hidden or output neuron performs two computations:\n",
    "    1. Computation of function signal going out of this neuron\n",
    "    2.  Computation of an estimate of the gradient vector\n",
    "\n",
    "\n",
    "* First let's consider the output layer...\n",
    "\n",
    "* Given a training set, $\\left\\{ \\mathbf{x}_n, d_n\\right\\}_{n = 1}^N$, we want to find the parameters of our network that minimizes the squared error: \n",
    " \\begin{equation}\n",
    " E(w) = \\frac{1}{2} \\sum_{n=1}^N (d_n - y_n)^2\n",
    " \\end{equation}\n",
    "\n",
    "* What is a common optimization approach to estimate the parameters that minimize an objective/error function? *gradient descent*\n",
    "* To use gradient descent, what do we need?  The analytic form of the gradient. \n",
    "\n",
    " \\begin{eqnarray}\n",
    " \\frac{ \\partial E}{\\partial w_i} &=& \\frac{\\partial}{\\partial w_i} \\left[ \\frac{1}{2} \\sum_{n=1}^N (d_n - y_n)^2 \\right]\\\\\n",
    " &=&  \\frac{1}{2} \\sum_{n=1}^N  \\frac{\\partial}{\\partial w_i}  (d_n - y_n)^2 \\\\\n",
    " &=&  \\frac{1}{2} \\sum_{n=1}^N   2(d_n - y_n) \\frac{\\partial}{\\partial w_i} (d_n - y_n) \\\\\n",
    "  &=&  \\sum_{n=1}^N   (d_n - y_n) \\left( \\frac{\\partial}{\\partial w_i} d_n -  \\frac{\\partial}{\\partial w_i} y_n \\right) \\\\\n",
    "    &=&  \\sum_{n=1}^N   (d_n - y_n) \\left(  -  \\frac{\\partial }{\\partial w_i} y_n \\right) \n",
    " \\end{eqnarray}\n",
    "\n",
    "* What is $y_n$ in terms of $w_i$?  (At first let's assume we have no hidden layers, only the output layer to deal with)\n",
    "\n",
    "\\begin{equation}\n",
    "y_n = \\phi(v_n) = \\phi(\\mathbf{w}^T \\mathbf{x}_n) \n",
    "\\end{equation} \n",
    "\n",
    "* Going back to computing our gradient... \n",
    " \\begin{eqnarray}\n",
    "    &=&  \\sum_{n=1}^N   (d_n - y_n) \\left(  -  \\frac{\\partial }{\\partial w_i} y_n \\right) \\\\\n",
    "    &=&  \\sum_{n=1}^N  - (d_n - y_n)   \\frac{\\partial y_n}{\\partial v_n} \\frac{\\partial v_n}{\\partial w_i} \n",
    " \\end{eqnarray}\n",
    "\n",
    "* So, $\\frac{\\partial y_n}{\\partial v_n}$ will depend on the form of the activation function we use.  If we use the sigmoid: $y_n = \\frac{1}{1 + \\exp(-\\alpha v_n)}$, then *what is* $\\frac{\\partial y_n}{\\partial v_n}$ ? \n",
    "\n",
    " \\begin{eqnarray}\n",
    " \\frac{\\partial y_n}{\\partial v_n} &=& \\frac{\\partial \\phi(v_n)}{\\partial v_n}\\\\\n",
    "  &=& \\frac{ \\partial }{\\partial v_n}  \\frac{1}{1 + \\exp(-\\alpha v_n)} \\\\\n",
    "  &=& \\frac{  \\left(1 + \\exp(- \\alpha v_n)\\right)\\left(\\frac{ \\partial }{\\partial v_n} 1\\right) - \\left(1\\right)\\left( \\frac{ \\partial }{\\partial v_n}  1 + \\exp(- \\alpha v_n) \\right)}{(1 + \\exp(-\\alpha v_n))^2}\\\\\n",
    "    &=& \\frac{  - \\frac{ \\partial }{\\partial v_n}  (1 + \\exp(- \\alpha v_n) ) }{(1 + \\exp(-\\alpha v_n))^2}\\\\\n",
    "    &=& \\frac{  -1  }{(1 + \\exp(-\\alpha v_n))^2} \\exp(-\\alpha v_n)(-\\alpha)\\\\\n",
    "    &=&\\frac{  1  }{1 + \\exp(-\\alpha v_n)} \\frac{  1  }{1 + \\exp(- \\alpha v_n)} \\exp(-\\alpha v_n)\\\\\n",
    "        &=&\\frac{  1  }{1 + \\exp(-\\alpha v_n)} \\frac{  \\exp(-\\alpha v_n)  }{1 + \\exp(-\\alpha v_n)}\\\\\n",
    "        &=& y_n (1-y_n)\n",
    " \\end{eqnarray}\n",
    "\n",
    "* Going back to computing our gradient... \n",
    " \\begin{eqnarray}\n",
    "    &=&  \\sum_{n=1}^N  - (d_n - y_n)   \\frac{\\partial y_n}{\\partial v_n} \\frac{\\partial v_n}{\\partial w_i} \\\\\n",
    "     &=&  \\sum_{n=1}^N  - (d_n - y_n)   y_n (1-y_n) \\frac{\\partial v_n}{\\partial w_i}\\\\\n",
    "     &=&  \\sum_{n=1}^N  - (d_n - y_n)   y_n (1-y_n) \\frac{\\partial }{\\partial w_i} \\mathbf{w}^T \\mathbf{x}_n\\\\\n",
    "     &=&  \\sum_{n=1}^N  - (d_n - y_n)   y_n (1-y_n) x_{ni}\n",
    " \\end{eqnarray}\n",
    "\n",
    "* *Now that we have the gradient, how do we use this to update the output layer weights in our MLP?*\n",
    "* *How will this update equation  (for the output layer) change if the network is a multilayer perceptron with hidden units?*\n",
    "* *Can you write this in vector form to update all weights simultaneously?*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation through hidden layers\n",
    "\n",
    "* Now to address hidden layers... We have to deal with the credit assignment problem. \n",
    "\n",
    "<img src=\"HiddenLayerImage.png\" width=\"500\">\n",
    "\n",
    "* Suppose we want to update $w_{ji}$ where $j$ is a hidden layer.  \n",
    "\n",
    "* The error objective function over all $N$ data points is\n",
    "\n",
    "\\begin{equation}\n",
    "E(n) = \\frac{1}{2}\\sum_{n=1}^N e_n^2 = \\sum_{n=1}^N \\left(d_n - y_n \\right)^2  = \\sum_{n=1}^N \\left(d_n - \\phi_n(v_n(n)) \\right)^2\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial E(n)}{\\partial w_{lj}} &=& \\frac{\\partial E(n)}{\\partial e_l(n)} \\frac{\\partial e_l(n)}{\\partial y_l(n)}\\frac{\\partial y_l(n)}{\\partial v_{l}(n)}\\frac{\\partial v_l(n)}{\\partial w_{lj}}\\\\\n",
    "&=&  [e_l][-1][\\phi^{\\prime}(v_l(n))][y_{jl}(n)] \\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "* Let's define a *local gradient* $\\delta_l(n)$:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\delta_l(n) &=& - \\frac{\\partial E(n)}{\\partial v_l(n)}\\\\\n",
    " &=&  e_l(n) \\phi^{\\prime}(v_l(n)) \n",
    " \\end{eqnarray}\n",
    "\n",
    "* Similarly, \n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\delta_j(n) &=& - \\frac{\\partial E(n)}{\\partial v_j(n)}\\\\\n",
    "&=& - \\frac{\\partial E(n)}{\\partial y_j(n)}\\frac{\\partial y_j(n)}{\\partial v_j(n)} \\\\\n",
    "&=& - \\frac{\\partial E(n)}{\\partial y_j(n)} \\phi^{\\prime}(v_j(n))  \n",
    " \\end{eqnarray}\n",
    "\n",
    "* Note that:\n",
    " \\begin{eqnarray}\n",
    " \\frac{\\partial E(n)}{\\partial y_j(n)} &=&  \\sum_{l}e_l(n)\\frac{\\partial e_l(n)}{\\partial y_j(n)} \\\\\n",
    " &=&  \\sum_{l}e_l(n)\\frac{\\partial e_l(n)}{\\partial v_l(n)} \\frac{\\partial v_l(n)}{\\partial y_j(n)} \\\\\n",
    "  &=&  \\sum_{l}e_l(n)[-\\phi^{\\prime}(v_l(n))][w_{lj}(n)]\n",
    "\\end{eqnarray}\n",
    "\n",
    "* So, \n",
    "\n",
    " \\begin{eqnarray}\n",
    " \\delta_j(n) &=& - \\frac{\\partial E(n)}{\\partial y_j(n)} \\phi^{\\prime}(v_j(n)) \\\\\n",
    " &=& - \\left[ \\sum_{l}e_l(n)[-\\phi^{\\prime}(v_l(n))][w_{lj}(n)] \\right]  \\phi^{\\prime}(v_j(n))\\\\ \n",
    " &=& \\phi^{\\prime}(v_j(n)) \\sum_l \\delta_l(n)w_{lj}(n)\n",
    "\\end{eqnarray}\n",
    "\n",
    "* So, you can write the gradient at a hidden neuron in terms of the local gradient and the connected neurons in the next layer\n",
    "\n",
    "\\begin{equation}\n",
    "\\delta w_{ij}(n) = \\eta \\delta_j(n) y_i(n)\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
